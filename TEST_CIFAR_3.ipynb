{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TEST_CIFAR_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPGNJ30uRFL3hvEJFO3bAGk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nbht98/attack_cat_or_dog_classification/blob/master/TEST_CIFAR_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRhFIVbdcLWj",
        "colab_type": "code",
        "outputId": "34699a9d-35e5-4b26-e14b-88d3a1ca2fa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "!pip3 install mia"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mia\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/12/f149a7cd43e49725921e9884363aa3cbfea8a49c319a944eb71d48973fa9/mia-0.1.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mia) (1.18.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from mia) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from mia) (0.22.2.post1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from mia) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from mia) (4.38.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->mia) (0.14.1)\n",
            "Building wheels for collected packages: mia\n",
            "  Building wheel for mia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mia: filename=mia-0.1.2-cp36-none-any.whl size=11079 sha256=d9285ffe673e16e68f22351baab0701aaf43ffb180f055766c1a8a12c872094a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/83/e4/baae7782aa0d2e45af485d25a7994bab3f76428e483252ce82\n",
            "Successfully built mia\n",
            "Installing collected packages: mia\n",
            "Successfully installed mia-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlYXFz4Pj_ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import library \n",
        "import numpy as np\n",
        "\n",
        "from absl import app\n",
        "from absl import flags\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from mia.estimators import ShadowModelBundle, AttackModelBundle, prepare_attack_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti0JsKCDkEpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_CLASSES = 10\n",
        "WIDTH = 32\n",
        "HEIGHT = 32\n",
        "CHANNELS = 3\n",
        "\n",
        "TARGET_EPOCHS = 100 # Number of epochs to train target and shadow models\n",
        "ATTACK_EPOCHS = 100 # Number of epochs to train attack models.\n",
        "NUM_SHADOWS = 3 # Number of epochs to train attack models."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bfxsA3ekKPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data():\n",
        "    \"\"\"Prepare CIFAR10 data.\"\"\"\n",
        "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "    y_train = tf.keras.utils.to_categorical(y_train)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test)\n",
        "    X_train = X_train.astype(\"float32\")\n",
        "    X_test = X_test.astype(\"float32\")\n",
        "    y_train = y_train.astype(\"float32\")\n",
        "    y_test = y_test.astype(\"float32\")\n",
        "    X_train /= 255\n",
        "    X_test /= 255\n",
        "    return (X_train, y_train), (X_test, y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv26T7n5kTFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def target_model_fn():\n",
        "  \"\"\"The architecture of the target (victim) model.\n",
        "  The attack is white-box, hence the attacker is assumed to know this architecture too.\"\"\"\n",
        "\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(\n",
        "      layers.Conv2D(\n",
        "          32,\n",
        "          (3, 3),\n",
        "          activation=\"relu\",\n",
        "          padding=\"same\",\n",
        "          input_shape=(WIDTH, HEIGHT, CHANNELS),\n",
        "      )\n",
        "  )\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation=\"relu\"))\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "\n",
        "  model.add(layers.Dense(512, activation=\"relu\"))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "\n",
        "  model.add(layers.Dense(NUM_CLASSES, activation=\"softmax\"))\n",
        "  model.compile(\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def attack_model_fn():\n",
        "  \"\"\"Attack model that takes target model predictions and predicts membership.\n",
        "  Following the original paper, this attack model is specific to the class of the input.\n",
        "  AttachModelBundle creates multiple instances of this model for each class.\n",
        "  \"\"\"\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(layers.Dense(128, activation=\"relu\", input_shape=(NUM_CLASSES,)))\n",
        "\n",
        "  model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
        "  model.add(layers.Dense(64, activation=\"relu\"))\n",
        "  model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
        "  model.add(layers.Dense(64, activation=\"relu\"))\n",
        "\n",
        "  model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "  model.compile(\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v71h_Ulukm7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "26daa61f-d151-4a06-dbea-8e5fb5b99a01"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = get_data()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 13s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QmA96tsFYvl",
        "colab_type": "code",
        "outputId": "09d88232-0b4a-4fce-dece-5a16963b8345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Train the target model.\n",
        "print(\"Training the target model...\")\n",
        "target_model = target_model_fn()\n",
        "target_model.load_weights(\"model900.h5\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the target model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMTGvufEksVz",
        "colab_type": "code",
        "outputId": "adf8fbe9-d321-4c8c-e4c2-7e746da6940b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "target_model.fit(\n",
        "    X_train, y_train, epochs=TARGET_EPOCHS, validation_split=0.1, verbose=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2448 - accuracy: 0.9216 - val_loss: 0.8413 - val_accuracy: 0.8072\n",
            "Epoch 2/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2450 - accuracy: 0.9225 - val_loss: 0.8545 - val_accuracy: 0.8016\n",
            "Epoch 3/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2306 - accuracy: 0.9266 - val_loss: 0.8969 - val_accuracy: 0.7968\n",
            "Epoch 4/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2427 - accuracy: 0.9241 - val_loss: 0.9124 - val_accuracy: 0.8002\n",
            "Epoch 5/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2463 - accuracy: 0.9226 - val_loss: 0.9072 - val_accuracy: 0.8098\n",
            "Epoch 6/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2384 - accuracy: 0.9257 - val_loss: 0.9480 - val_accuracy: 0.8036\n",
            "Epoch 7/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2552 - accuracy: 0.9222 - val_loss: 0.8429 - val_accuracy: 0.8016\n",
            "Epoch 8/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2349 - accuracy: 0.9270 - val_loss: 0.8306 - val_accuracy: 0.8000\n",
            "Epoch 9/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2368 - accuracy: 0.9261 - val_loss: 0.9882 - val_accuracy: 0.8072\n",
            "Epoch 10/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2456 - accuracy: 0.9242 - val_loss: 0.8671 - val_accuracy: 0.8012\n",
            "Epoch 11/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2386 - accuracy: 0.9243 - val_loss: 0.9837 - val_accuracy: 0.7984\n",
            "Epoch 12/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2479 - accuracy: 0.9231 - val_loss: 0.8645 - val_accuracy: 0.8070\n",
            "Epoch 13/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2328 - accuracy: 0.9282 - val_loss: 0.8395 - val_accuracy: 0.7974\n",
            "Epoch 14/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2413 - accuracy: 0.9242 - val_loss: 0.8540 - val_accuracy: 0.8054\n",
            "Epoch 15/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2437 - accuracy: 0.9244 - val_loss: 0.8802 - val_accuracy: 0.8042\n",
            "Epoch 16/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2353 - accuracy: 0.9263 - val_loss: 0.9206 - val_accuracy: 0.7974\n",
            "Epoch 17/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2327 - accuracy: 0.9268 - val_loss: 0.9378 - val_accuracy: 0.7952\n",
            "Epoch 18/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2295 - accuracy: 0.9266 - val_loss: 0.8876 - val_accuracy: 0.8046\n",
            "Epoch 19/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2354 - accuracy: 0.9260 - val_loss: 0.8326 - val_accuracy: 0.7978\n",
            "Epoch 20/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2381 - accuracy: 0.9247 - val_loss: 0.8439 - val_accuracy: 0.8096\n",
            "Epoch 21/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2447 - accuracy: 0.9231 - val_loss: 0.9489 - val_accuracy: 0.8010\n",
            "Epoch 22/300\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.2353 - accuracy: 0.9261 - val_loss: 0.8633 - val_accuracy: 0.8000\n",
            "Epoch 23/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2430 - accuracy: 0.9242 - val_loss: 0.9368 - val_accuracy: 0.7944\n",
            "Epoch 24/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2482 - accuracy: 0.9228 - val_loss: 0.8946 - val_accuracy: 0.7992\n",
            "Epoch 25/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2446 - accuracy: 0.9246 - val_loss: 0.9165 - val_accuracy: 0.7936\n",
            "Epoch 26/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2464 - accuracy: 0.9246 - val_loss: 0.8759 - val_accuracy: 0.7992\n",
            "Epoch 27/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2314 - accuracy: 0.9268 - val_loss: 0.8997 - val_accuracy: 0.8060\n",
            "Epoch 28/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2393 - accuracy: 0.9262 - val_loss: 0.8892 - val_accuracy: 0.8016\n",
            "Epoch 29/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2524 - accuracy: 0.9214 - val_loss: 0.8820 - val_accuracy: 0.8028\n",
            "Epoch 30/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2432 - accuracy: 0.9230 - val_loss: 0.9731 - val_accuracy: 0.8054\n",
            "Epoch 31/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2346 - accuracy: 0.9275 - val_loss: 0.9098 - val_accuracy: 0.8038\n",
            "Epoch 32/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2390 - accuracy: 0.9247 - val_loss: 0.8834 - val_accuracy: 0.7988\n",
            "Epoch 33/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2415 - accuracy: 0.9252 - val_loss: 0.8752 - val_accuracy: 0.7952\n",
            "Epoch 34/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2387 - accuracy: 0.9265 - val_loss: 0.9084 - val_accuracy: 0.7986\n",
            "Epoch 35/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2364 - accuracy: 0.9252 - val_loss: 0.9984 - val_accuracy: 0.8008\n",
            "Epoch 36/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2527 - accuracy: 0.9231 - val_loss: 0.8372 - val_accuracy: 0.8016\n",
            "Epoch 37/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2358 - accuracy: 0.9247 - val_loss: 0.8984 - val_accuracy: 0.8012\n",
            "Epoch 38/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2387 - accuracy: 0.9252 - val_loss: 0.8914 - val_accuracy: 0.8038\n",
            "Epoch 39/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2379 - accuracy: 0.9260 - val_loss: 0.8277 - val_accuracy: 0.8042\n",
            "Epoch 40/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2378 - accuracy: 0.9257 - val_loss: 0.8953 - val_accuracy: 0.8076\n",
            "Epoch 41/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2416 - accuracy: 0.9250 - val_loss: 0.9250 - val_accuracy: 0.8008\n",
            "Epoch 42/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2367 - accuracy: 0.9252 - val_loss: 0.9637 - val_accuracy: 0.7996\n",
            "Epoch 43/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2395 - accuracy: 0.9243 - val_loss: 0.8083 - val_accuracy: 0.8020\n",
            "Epoch 44/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2332 - accuracy: 0.9267 - val_loss: 0.9032 - val_accuracy: 0.7942\n",
            "Epoch 45/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2418 - accuracy: 0.9240 - val_loss: 0.8392 - val_accuracy: 0.7996\n",
            "Epoch 46/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2441 - accuracy: 0.9247 - val_loss: 0.8658 - val_accuracy: 0.7968\n",
            "Epoch 47/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2361 - accuracy: 0.9265 - val_loss: 0.8928 - val_accuracy: 0.8026\n",
            "Epoch 48/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2434 - accuracy: 0.9234 - val_loss: 0.9599 - val_accuracy: 0.8064\n",
            "Epoch 49/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2420 - accuracy: 0.9254 - val_loss: 0.8468 - val_accuracy: 0.7908\n",
            "Epoch 50/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2444 - accuracy: 0.9229 - val_loss: 0.8444 - val_accuracy: 0.8122\n",
            "Epoch 51/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2499 - accuracy: 0.9224 - val_loss: 0.8638 - val_accuracy: 0.8062\n",
            "Epoch 52/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2344 - accuracy: 0.9257 - val_loss: 0.8358 - val_accuracy: 0.8018\n",
            "Epoch 53/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2454 - accuracy: 0.9240 - val_loss: 0.7804 - val_accuracy: 0.7980\n",
            "Epoch 54/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2380 - accuracy: 0.9248 - val_loss: 0.9270 - val_accuracy: 0.7978\n",
            "Epoch 55/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2443 - accuracy: 0.9250 - val_loss: 0.8291 - val_accuracy: 0.8016\n",
            "Epoch 56/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2430 - accuracy: 0.9226 - val_loss: 0.9378 - val_accuracy: 0.7920\n",
            "Epoch 57/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2412 - accuracy: 0.9240 - val_loss: 0.8143 - val_accuracy: 0.8088\n",
            "Epoch 58/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2267 - accuracy: 0.9282 - val_loss: 0.8687 - val_accuracy: 0.8070\n",
            "Epoch 59/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2342 - accuracy: 0.9258 - val_loss: 0.8575 - val_accuracy: 0.7992\n",
            "Epoch 60/300\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.2456 - accuracy: 0.9237 - val_loss: 0.8847 - val_accuracy: 0.8032\n",
            "Epoch 61/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2336 - accuracy: 0.9261 - val_loss: 0.8746 - val_accuracy: 0.7974\n",
            "Epoch 62/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2447 - accuracy: 0.9254 - val_loss: 0.8830 - val_accuracy: 0.8038\n",
            "Epoch 63/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2404 - accuracy: 0.9255 - val_loss: 0.8487 - val_accuracy: 0.8046\n",
            "Epoch 64/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2518 - accuracy: 0.9217 - val_loss: 0.8729 - val_accuracy: 0.8086\n",
            "Epoch 65/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2405 - accuracy: 0.9244 - val_loss: 0.8888 - val_accuracy: 0.8062\n",
            "Epoch 66/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2365 - accuracy: 0.9247 - val_loss: 0.9340 - val_accuracy: 0.8010\n",
            "Epoch 67/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2388 - accuracy: 0.9254 - val_loss: 0.9530 - val_accuracy: 0.7990\n",
            "Epoch 68/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2384 - accuracy: 0.9256 - val_loss: 0.9416 - val_accuracy: 0.8042\n",
            "Epoch 69/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2386 - accuracy: 0.9254 - val_loss: 0.9033 - val_accuracy: 0.8042\n",
            "Epoch 70/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2392 - accuracy: 0.9240 - val_loss: 0.8843 - val_accuracy: 0.8028\n",
            "Epoch 71/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2393 - accuracy: 0.9258 - val_loss: 0.7840 - val_accuracy: 0.8018\n",
            "Epoch 72/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2426 - accuracy: 0.9257 - val_loss: 0.8724 - val_accuracy: 0.7958\n",
            "Epoch 73/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2449 - accuracy: 0.9239 - val_loss: 0.8967 - val_accuracy: 0.7936\n",
            "Epoch 74/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2716 - accuracy: 0.9172 - val_loss: 0.9391 - val_accuracy: 0.8080\n",
            "Epoch 75/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2253 - accuracy: 0.9292 - val_loss: 0.9123 - val_accuracy: 0.7916\n",
            "Epoch 76/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2383 - accuracy: 0.9258 - val_loss: 0.9484 - val_accuracy: 0.7946\n",
            "Epoch 77/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2352 - accuracy: 0.9279 - val_loss: 0.9001 - val_accuracy: 0.8044\n",
            "Epoch 78/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2453 - accuracy: 0.9250 - val_loss: 0.8580 - val_accuracy: 0.8096\n",
            "Epoch 79/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2283 - accuracy: 0.9287 - val_loss: 0.8481 - val_accuracy: 0.8030\n",
            "Epoch 80/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2378 - accuracy: 0.9269 - val_loss: 0.8308 - val_accuracy: 0.8066\n",
            "Epoch 81/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2341 - accuracy: 0.9251 - val_loss: 0.8626 - val_accuracy: 0.8004\n",
            "Epoch 82/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2401 - accuracy: 0.9253 - val_loss: 0.8290 - val_accuracy: 0.8000\n",
            "Epoch 83/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2347 - accuracy: 0.9279 - val_loss: 0.8394 - val_accuracy: 0.8008\n",
            "Epoch 84/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2359 - accuracy: 0.9278 - val_loss: 0.8592 - val_accuracy: 0.8030\n",
            "Epoch 85/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2451 - accuracy: 0.9237 - val_loss: 0.8896 - val_accuracy: 0.8070\n",
            "Epoch 86/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2373 - accuracy: 0.9260 - val_loss: 0.9151 - val_accuracy: 0.8012\n",
            "Epoch 87/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2379 - accuracy: 0.9254 - val_loss: 0.8235 - val_accuracy: 0.8066\n",
            "Epoch 88/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2362 - accuracy: 0.9260 - val_loss: 0.8541 - val_accuracy: 0.8080\n",
            "Epoch 89/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2412 - accuracy: 0.9264 - val_loss: 0.9954 - val_accuracy: 0.7956\n",
            "Epoch 90/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2460 - accuracy: 0.9242 - val_loss: 0.9028 - val_accuracy: 0.8030\n",
            "Epoch 91/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2367 - accuracy: 0.9258 - val_loss: 0.8470 - val_accuracy: 0.8080\n",
            "Epoch 92/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2448 - accuracy: 0.9228 - val_loss: 0.8973 - val_accuracy: 0.8094\n",
            "Epoch 93/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2368 - accuracy: 0.9271 - val_loss: 0.8966 - val_accuracy: 0.8056\n",
            "Epoch 94/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2367 - accuracy: 0.9254 - val_loss: 0.8884 - val_accuracy: 0.8006\n",
            "Epoch 95/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2316 - accuracy: 0.9272 - val_loss: 0.9924 - val_accuracy: 0.8052\n",
            "Epoch 96/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2308 - accuracy: 0.9285 - val_loss: 0.9531 - val_accuracy: 0.8026\n",
            "Epoch 97/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2472 - accuracy: 0.9241 - val_loss: 0.8607 - val_accuracy: 0.8056\n",
            "Epoch 98/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2420 - accuracy: 0.9238 - val_loss: 0.9167 - val_accuracy: 0.8064\n",
            "Epoch 99/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2355 - accuracy: 0.9252 - val_loss: 0.9269 - val_accuracy: 0.8028\n",
            "Epoch 100/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2334 - accuracy: 0.9274 - val_loss: 0.8770 - val_accuracy: 0.7916\n",
            "Epoch 101/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2301 - accuracy: 0.9273 - val_loss: 0.7874 - val_accuracy: 0.7962\n",
            "Epoch 102/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2382 - accuracy: 0.9252 - val_loss: 0.8987 - val_accuracy: 0.7964\n",
            "Epoch 103/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2314 - accuracy: 0.9296 - val_loss: 0.9692 - val_accuracy: 0.8032\n",
            "Epoch 104/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2348 - accuracy: 0.9255 - val_loss: 0.9289 - val_accuracy: 0.8040\n",
            "Epoch 105/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2356 - accuracy: 0.9276 - val_loss: 0.8209 - val_accuracy: 0.7938\n",
            "Epoch 106/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2360 - accuracy: 0.9253 - val_loss: 0.8739 - val_accuracy: 0.8084\n",
            "Epoch 107/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2385 - accuracy: 0.9253 - val_loss: 0.9072 - val_accuracy: 0.8048\n",
            "Epoch 108/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2509 - accuracy: 0.9233 - val_loss: 0.8839 - val_accuracy: 0.8096\n",
            "Epoch 109/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2256 - accuracy: 0.9292 - val_loss: 0.8637 - val_accuracy: 0.8060\n",
            "Epoch 110/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2297 - accuracy: 0.9297 - val_loss: 0.8481 - val_accuracy: 0.8110\n",
            "Epoch 111/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2383 - accuracy: 0.9272 - val_loss: 0.8522 - val_accuracy: 0.8098\n",
            "Epoch 112/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2370 - accuracy: 0.9259 - val_loss: 0.9026 - val_accuracy: 0.8016\n",
            "Epoch 113/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2264 - accuracy: 0.9290 - val_loss: 0.9002 - val_accuracy: 0.8024\n",
            "Epoch 114/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2428 - accuracy: 0.9244 - val_loss: 0.8078 - val_accuracy: 0.7946\n",
            "Epoch 115/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2353 - accuracy: 0.9263 - val_loss: 0.8642 - val_accuracy: 0.7998\n",
            "Epoch 116/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2427 - accuracy: 0.9241 - val_loss: 1.0178 - val_accuracy: 0.8008\n",
            "Epoch 117/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2436 - accuracy: 0.9257 - val_loss: 0.9134 - val_accuracy: 0.8014\n",
            "Epoch 118/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2392 - accuracy: 0.9264 - val_loss: 0.8409 - val_accuracy: 0.8082\n",
            "Epoch 119/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2359 - accuracy: 0.9260 - val_loss: 0.9135 - val_accuracy: 0.8078\n",
            "Epoch 120/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2487 - accuracy: 0.9236 - val_loss: 0.8959 - val_accuracy: 0.8066\n",
            "Epoch 121/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2427 - accuracy: 0.9252 - val_loss: 0.7960 - val_accuracy: 0.8086\n",
            "Epoch 122/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2299 - accuracy: 0.9277 - val_loss: 0.9022 - val_accuracy: 0.8006\n",
            "Epoch 123/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2326 - accuracy: 0.9276 - val_loss: 0.8504 - val_accuracy: 0.7996\n",
            "Epoch 124/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2422 - accuracy: 0.9237 - val_loss: 0.9090 - val_accuracy: 0.8000\n",
            "Epoch 125/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2398 - accuracy: 0.9250 - val_loss: 0.9173 - val_accuracy: 0.8052\n",
            "Epoch 126/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2367 - accuracy: 0.9263 - val_loss: 0.8758 - val_accuracy: 0.8104\n",
            "Epoch 127/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2442 - accuracy: 0.9247 - val_loss: 0.8796 - val_accuracy: 0.8106\n",
            "Epoch 128/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2440 - accuracy: 0.9241 - val_loss: 0.8923 - val_accuracy: 0.8094\n",
            "Epoch 129/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2339 - accuracy: 0.9284 - val_loss: 0.8907 - val_accuracy: 0.8076\n",
            "Epoch 130/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2408 - accuracy: 0.9250 - val_loss: 0.9014 - val_accuracy: 0.8012\n",
            "Epoch 131/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2330 - accuracy: 0.9280 - val_loss: 0.8835 - val_accuracy: 0.8048\n",
            "Epoch 132/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2426 - accuracy: 0.9243 - val_loss: 0.9028 - val_accuracy: 0.7964\n",
            "Epoch 133/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2391 - accuracy: 0.9251 - val_loss: 0.8944 - val_accuracy: 0.8092\n",
            "Epoch 134/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2314 - accuracy: 0.9285 - val_loss: 0.8290 - val_accuracy: 0.8074\n",
            "Epoch 135/300\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.2362 - accuracy: 0.9255 - val_loss: 0.8670 - val_accuracy: 0.8016\n",
            "Epoch 136/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2325 - accuracy: 0.9280 - val_loss: 0.9613 - val_accuracy: 0.8068\n",
            "Epoch 137/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2317 - accuracy: 0.9275 - val_loss: 0.8632 - val_accuracy: 0.8078\n",
            "Epoch 138/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2402 - accuracy: 0.9267 - val_loss: 0.8783 - val_accuracy: 0.8056\n",
            "Epoch 139/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2464 - accuracy: 0.9256 - val_loss: 0.8521 - val_accuracy: 0.8066\n",
            "Epoch 140/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2245 - accuracy: 0.9300 - val_loss: 0.9126 - val_accuracy: 0.8038\n",
            "Epoch 141/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2418 - accuracy: 0.9243 - val_loss: 0.9304 - val_accuracy: 0.8074\n",
            "Epoch 142/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2332 - accuracy: 0.9267 - val_loss: 0.9385 - val_accuracy: 0.8054\n",
            "Epoch 143/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2399 - accuracy: 0.9258 - val_loss: 0.9108 - val_accuracy: 0.8072\n",
            "Epoch 144/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2335 - accuracy: 0.9258 - val_loss: 0.8557 - val_accuracy: 0.8094\n",
            "Epoch 145/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2413 - accuracy: 0.9276 - val_loss: 0.8037 - val_accuracy: 0.8018\n",
            "Epoch 146/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2672 - accuracy: 0.9189 - val_loss: 0.8606 - val_accuracy: 0.8034\n",
            "Epoch 147/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2458 - accuracy: 0.9243 - val_loss: 0.8948 - val_accuracy: 0.7980\n",
            "Epoch 148/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2379 - accuracy: 0.9254 - val_loss: 0.8903 - val_accuracy: 0.7958\n",
            "Epoch 149/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2343 - accuracy: 0.9283 - val_loss: 0.9255 - val_accuracy: 0.8018\n",
            "Epoch 150/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3033 - accuracy: 0.9083 - val_loss: 0.8697 - val_accuracy: 0.7914\n",
            "Epoch 151/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2357 - accuracy: 0.9282 - val_loss: 0.8940 - val_accuracy: 0.8082\n",
            "Epoch 152/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2284 - accuracy: 0.9291 - val_loss: 0.8658 - val_accuracy: 0.8016\n",
            "Epoch 153/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2277 - accuracy: 0.9294 - val_loss: 0.8845 - val_accuracy: 0.7980\n",
            "Epoch 154/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2398 - accuracy: 0.9260 - val_loss: 0.8029 - val_accuracy: 0.8126\n",
            "Epoch 155/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2365 - accuracy: 0.9253 - val_loss: 0.8359 - val_accuracy: 0.7968\n",
            "Epoch 156/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2329 - accuracy: 0.9273 - val_loss: 0.9734 - val_accuracy: 0.7904\n",
            "Epoch 157/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2284 - accuracy: 0.9267 - val_loss: 0.9210 - val_accuracy: 0.8050\n",
            "Epoch 158/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2452 - accuracy: 0.9240 - val_loss: 1.0131 - val_accuracy: 0.8032\n",
            "Epoch 159/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2341 - accuracy: 0.9291 - val_loss: 0.9056 - val_accuracy: 0.8040\n",
            "Epoch 160/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2435 - accuracy: 0.9230 - val_loss: 0.9443 - val_accuracy: 0.7964\n",
            "Epoch 161/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2456 - accuracy: 0.9246 - val_loss: 1.0246 - val_accuracy: 0.7986\n",
            "Epoch 162/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2327 - accuracy: 0.9281 - val_loss: 0.8563 - val_accuracy: 0.8040\n",
            "Epoch 163/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2430 - accuracy: 0.9250 - val_loss: 0.9077 - val_accuracy: 0.8036\n",
            "Epoch 164/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2489 - accuracy: 0.9243 - val_loss: 0.8979 - val_accuracy: 0.8126\n",
            "Epoch 165/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2326 - accuracy: 0.9282 - val_loss: 0.7935 - val_accuracy: 0.8090\n",
            "Epoch 166/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2343 - accuracy: 0.9263 - val_loss: 0.8918 - val_accuracy: 0.8010\n",
            "Epoch 167/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2436 - accuracy: 0.9246 - val_loss: 0.8445 - val_accuracy: 0.8134\n",
            "Epoch 168/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2382 - accuracy: 0.9256 - val_loss: 0.8078 - val_accuracy: 0.8104\n",
            "Epoch 169/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2413 - accuracy: 0.9245 - val_loss: 0.8587 - val_accuracy: 0.8002\n",
            "Epoch 170/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2326 - accuracy: 0.9281 - val_loss: 0.8991 - val_accuracy: 0.8022\n",
            "Epoch 171/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2451 - accuracy: 0.9241 - val_loss: 0.8028 - val_accuracy: 0.8056\n",
            "Epoch 172/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2458 - accuracy: 0.9252 - val_loss: 1.0123 - val_accuracy: 0.8104\n",
            "Epoch 173/300\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.2414 - accuracy: 0.9245 - val_loss: 0.9011 - val_accuracy: 0.8080\n",
            "Epoch 174/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2333 - accuracy: 0.9259 - val_loss: 0.9282 - val_accuracy: 0.8134\n",
            "Epoch 175/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2531 - accuracy: 0.9220 - val_loss: 0.8897 - val_accuracy: 0.8074\n",
            "Epoch 176/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2269 - accuracy: 0.9288 - val_loss: 0.9225 - val_accuracy: 0.8000\n",
            "Epoch 177/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2392 - accuracy: 0.9258 - val_loss: 0.9292 - val_accuracy: 0.8118\n",
            "Epoch 178/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2347 - accuracy: 0.9257 - val_loss: 0.8330 - val_accuracy: 0.8094\n",
            "Epoch 179/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2446 - accuracy: 0.9245 - val_loss: 0.9293 - val_accuracy: 0.8012\n",
            "Epoch 180/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2453 - accuracy: 0.9241 - val_loss: 0.8913 - val_accuracy: 0.7970\n",
            "Epoch 181/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2399 - accuracy: 0.9256 - val_loss: 0.9841 - val_accuracy: 0.7994\n",
            "Epoch 182/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2436 - accuracy: 0.9253 - val_loss: 0.9698 - val_accuracy: 0.8030\n",
            "Epoch 183/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2327 - accuracy: 0.9274 - val_loss: 0.8136 - val_accuracy: 0.8038\n",
            "Epoch 184/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2387 - accuracy: 0.9262 - val_loss: 0.8360 - val_accuracy: 0.8026\n",
            "Epoch 185/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2295 - accuracy: 0.9282 - val_loss: 0.9770 - val_accuracy: 0.8068\n",
            "Epoch 186/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2334 - accuracy: 0.9260 - val_loss: 0.9704 - val_accuracy: 0.8016\n",
            "Epoch 187/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2420 - accuracy: 0.9252 - val_loss: 0.8717 - val_accuracy: 0.8068\n",
            "Epoch 188/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2485 - accuracy: 0.9243 - val_loss: 0.8723 - val_accuracy: 0.7926\n",
            "Epoch 189/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2410 - accuracy: 0.9249 - val_loss: 0.8624 - val_accuracy: 0.8050\n",
            "Epoch 190/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2329 - accuracy: 0.9268 - val_loss: 0.8963 - val_accuracy: 0.8006\n",
            "Epoch 191/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2464 - accuracy: 0.9233 - val_loss: 0.9049 - val_accuracy: 0.8080\n",
            "Epoch 192/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2483 - accuracy: 0.9230 - val_loss: 0.8638 - val_accuracy: 0.8038\n",
            "Epoch 193/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2457 - accuracy: 0.9219 - val_loss: 0.8420 - val_accuracy: 0.7960\n",
            "Epoch 194/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2853 - accuracy: 0.9190 - val_loss: 0.8591 - val_accuracy: 0.7750\n",
            "Epoch 195/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2901 - accuracy: 0.9100 - val_loss: 0.8551 - val_accuracy: 0.8054\n",
            "Epoch 196/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2369 - accuracy: 0.9269 - val_loss: 0.8671 - val_accuracy: 0.7998\n",
            "Epoch 197/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2390 - accuracy: 0.9270 - val_loss: 0.8229 - val_accuracy: 0.8060\n",
            "Epoch 198/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2364 - accuracy: 0.9267 - val_loss: 0.8944 - val_accuracy: 0.8022\n",
            "Epoch 199/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2302 - accuracy: 0.9283 - val_loss: 0.9091 - val_accuracy: 0.7974\n",
            "Epoch 200/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2451 - accuracy: 0.9246 - val_loss: 0.8368 - val_accuracy: 0.8030\n",
            "Epoch 201/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2355 - accuracy: 0.9280 - val_loss: 0.9240 - val_accuracy: 0.7934\n",
            "Epoch 202/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2313 - accuracy: 0.9283 - val_loss: 0.9148 - val_accuracy: 0.8004\n",
            "Epoch 203/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2317 - accuracy: 0.9261 - val_loss: 0.7693 - val_accuracy: 0.8022\n",
            "Epoch 204/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2397 - accuracy: 0.9257 - val_loss: 0.8942 - val_accuracy: 0.8058\n",
            "Epoch 205/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2265 - accuracy: 0.9292 - val_loss: 0.8950 - val_accuracy: 0.8032\n",
            "Epoch 206/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2352 - accuracy: 0.9267 - val_loss: 0.9522 - val_accuracy: 0.8072\n",
            "Epoch 207/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2350 - accuracy: 0.9274 - val_loss: 0.9019 - val_accuracy: 0.7974\n",
            "Epoch 208/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2343 - accuracy: 0.9281 - val_loss: 0.8712 - val_accuracy: 0.8018\n",
            "Epoch 209/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2432 - accuracy: 0.9243 - val_loss: 0.8680 - val_accuracy: 0.7932\n",
            "Epoch 210/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2312 - accuracy: 0.9278 - val_loss: 0.9248 - val_accuracy: 0.7952\n",
            "Epoch 211/300\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.2382 - accuracy: 0.9250 - val_loss: 0.9051 - val_accuracy: 0.8048\n",
            "Epoch 212/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2359 - accuracy: 0.9264 - val_loss: 0.9242 - val_accuracy: 0.8026\n",
            "Epoch 213/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2270 - accuracy: 0.9294 - val_loss: 0.8776 - val_accuracy: 0.8086\n",
            "Epoch 214/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2362 - accuracy: 0.9267 - val_loss: 0.8967 - val_accuracy: 0.7996\n",
            "Epoch 215/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2445 - accuracy: 0.9230 - val_loss: 0.8375 - val_accuracy: 0.8038\n",
            "Epoch 216/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2338 - accuracy: 0.9272 - val_loss: 0.9169 - val_accuracy: 0.8048\n",
            "Epoch 217/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2506 - accuracy: 0.9233 - val_loss: 0.9879 - val_accuracy: 0.8028\n",
            "Epoch 218/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2368 - accuracy: 0.9267 - val_loss: 0.9213 - val_accuracy: 0.8006\n",
            "Epoch 219/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2378 - accuracy: 0.9271 - val_loss: 0.8777 - val_accuracy: 0.8022\n",
            "Epoch 220/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2349 - accuracy: 0.9265 - val_loss: 0.8097 - val_accuracy: 0.7974\n",
            "Epoch 221/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2402 - accuracy: 0.9252 - val_loss: 0.7998 - val_accuracy: 0.8032\n",
            "Epoch 222/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2397 - accuracy: 0.9256 - val_loss: 0.8439 - val_accuracy: 0.7982\n",
            "Epoch 223/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2449 - accuracy: 0.9240 - val_loss: 0.8021 - val_accuracy: 0.8050\n",
            "Epoch 224/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2427 - accuracy: 0.9254 - val_loss: 0.9341 - val_accuracy: 0.8030\n",
            "Epoch 225/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2281 - accuracy: 0.9288 - val_loss: 0.8830 - val_accuracy: 0.8066\n",
            "Epoch 226/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2405 - accuracy: 0.9250 - val_loss: 0.8416 - val_accuracy: 0.8066\n",
            "Epoch 227/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2353 - accuracy: 0.9262 - val_loss: 0.9369 - val_accuracy: 0.8104\n",
            "Epoch 228/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2277 - accuracy: 0.9299 - val_loss: 0.8986 - val_accuracy: 0.8040\n",
            "Epoch 229/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2375 - accuracy: 0.9265 - val_loss: 0.8887 - val_accuracy: 0.8042\n",
            "Epoch 230/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2313 - accuracy: 0.9274 - val_loss: 0.9480 - val_accuracy: 0.8008\n",
            "Epoch 231/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2529 - accuracy: 0.9213 - val_loss: 0.9607 - val_accuracy: 0.8014\n",
            "Epoch 232/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2325 - accuracy: 0.9265 - val_loss: 0.8975 - val_accuracy: 0.8074\n",
            "Epoch 233/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2342 - accuracy: 0.9282 - val_loss: 0.9028 - val_accuracy: 0.7964\n",
            "Epoch 234/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2494 - accuracy: 0.9245 - val_loss: 0.8483 - val_accuracy: 0.8016\n",
            "Epoch 235/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2438 - accuracy: 0.9258 - val_loss: 0.8039 - val_accuracy: 0.8060\n",
            "Epoch 236/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2309 - accuracy: 0.9271 - val_loss: 0.9114 - val_accuracy: 0.7968\n",
            "Epoch 237/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2249 - accuracy: 0.9304 - val_loss: 0.9173 - val_accuracy: 0.8074\n",
            "Epoch 238/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2510 - accuracy: 0.9235 - val_loss: 0.8029 - val_accuracy: 0.8010\n",
            "Epoch 239/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2201 - accuracy: 0.9320 - val_loss: 0.9168 - val_accuracy: 0.8066\n",
            "Epoch 240/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2397 - accuracy: 0.9260 - val_loss: 0.9000 - val_accuracy: 0.8080\n",
            "Epoch 241/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2403 - accuracy: 0.9254 - val_loss: 0.9620 - val_accuracy: 0.8020\n",
            "Epoch 242/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2427 - accuracy: 0.9250 - val_loss: 0.9936 - val_accuracy: 0.8036\n",
            "Epoch 243/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2422 - accuracy: 0.9247 - val_loss: 0.9327 - val_accuracy: 0.8048\n",
            "Epoch 244/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2307 - accuracy: 0.9284 - val_loss: 0.9546 - val_accuracy: 0.8048\n",
            "Epoch 245/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2334 - accuracy: 0.9265 - val_loss: 0.9039 - val_accuracy: 0.8088\n",
            "Epoch 246/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2457 - accuracy: 0.9236 - val_loss: 0.8752 - val_accuracy: 0.8008\n",
            "Epoch 247/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2352 - accuracy: 0.9267 - val_loss: 0.9152 - val_accuracy: 0.8052\n",
            "Epoch 248/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2455 - accuracy: 0.9237 - val_loss: 0.8649 - val_accuracy: 0.7962\n",
            "Epoch 249/300\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.2382 - accuracy: 0.9255 - val_loss: 0.8613 - val_accuracy: 0.7848\n",
            "Epoch 250/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2357 - accuracy: 0.9266 - val_loss: 0.8919 - val_accuracy: 0.7966\n",
            "Epoch 251/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2387 - accuracy: 0.9262 - val_loss: 0.9283 - val_accuracy: 0.8038\n",
            "Epoch 252/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2453 - accuracy: 0.9234 - val_loss: 0.8588 - val_accuracy: 0.7958\n",
            "Epoch 253/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2312 - accuracy: 0.9275 - val_loss: 0.8969 - val_accuracy: 0.8018\n",
            "Epoch 254/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2477 - accuracy: 0.9233 - val_loss: 0.8950 - val_accuracy: 0.8004\n",
            "Epoch 255/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2341 - accuracy: 0.9280 - val_loss: 0.9736 - val_accuracy: 0.7982\n",
            "Epoch 256/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2318 - accuracy: 0.9274 - val_loss: 0.8248 - val_accuracy: 0.8026\n",
            "Epoch 257/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2438 - accuracy: 0.9248 - val_loss: 0.9584 - val_accuracy: 0.8030\n",
            "Epoch 258/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2259 - accuracy: 0.9300 - val_loss: 0.8484 - val_accuracy: 0.8040\n",
            "Epoch 259/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2430 - accuracy: 0.9245 - val_loss: 0.8623 - val_accuracy: 0.8026\n",
            "Epoch 260/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2384 - accuracy: 0.9257 - val_loss: 0.9063 - val_accuracy: 0.8030\n",
            "Epoch 261/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2407 - accuracy: 0.9265 - val_loss: 0.8806 - val_accuracy: 0.8074\n",
            "Epoch 262/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2362 - accuracy: 0.9280 - val_loss: 0.8943 - val_accuracy: 0.8004\n",
            "Epoch 263/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2406 - accuracy: 0.9252 - val_loss: 0.8290 - val_accuracy: 0.8090\n",
            "Epoch 264/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2324 - accuracy: 0.9267 - val_loss: 0.8584 - val_accuracy: 0.8090\n",
            "Epoch 265/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2379 - accuracy: 0.9269 - val_loss: 0.8839 - val_accuracy: 0.8034\n",
            "Epoch 266/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2352 - accuracy: 0.9277 - val_loss: 0.8914 - val_accuracy: 0.7928\n",
            "Epoch 267/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2392 - accuracy: 0.9259 - val_loss: 0.8722 - val_accuracy: 0.8000\n",
            "Epoch 268/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2322 - accuracy: 0.9282 - val_loss: 0.8713 - val_accuracy: 0.8002\n",
            "Epoch 269/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2293 - accuracy: 0.9294 - val_loss: 0.8709 - val_accuracy: 0.8040\n",
            "Epoch 270/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2278 - accuracy: 0.9287 - val_loss: 0.9051 - val_accuracy: 0.8038\n",
            "Epoch 271/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2434 - accuracy: 0.9251 - val_loss: 0.8469 - val_accuracy: 0.8032\n",
            "Epoch 272/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2308 - accuracy: 0.9277 - val_loss: 0.9729 - val_accuracy: 0.8080\n",
            "Epoch 273/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2514 - accuracy: 0.9231 - val_loss: 0.9093 - val_accuracy: 0.8062\n",
            "Epoch 274/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2324 - accuracy: 0.9255 - val_loss: 0.9027 - val_accuracy: 0.8010\n",
            "Epoch 275/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2337 - accuracy: 0.9273 - val_loss: 1.0718 - val_accuracy: 0.7986\n",
            "Epoch 276/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2375 - accuracy: 0.9267 - val_loss: 0.9069 - val_accuracy: 0.7954\n",
            "Epoch 277/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2418 - accuracy: 0.9258 - val_loss: 0.9773 - val_accuracy: 0.8062\n",
            "Epoch 278/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2335 - accuracy: 0.9284 - val_loss: 0.8761 - val_accuracy: 0.8008\n",
            "Epoch 279/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2308 - accuracy: 0.9278 - val_loss: 0.8468 - val_accuracy: 0.8076\n",
            "Epoch 280/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2508 - accuracy: 0.9225 - val_loss: 0.8770 - val_accuracy: 0.8102\n",
            "Epoch 281/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2444 - accuracy: 0.9240 - val_loss: 0.9161 - val_accuracy: 0.8064\n",
            "Epoch 282/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2276 - accuracy: 0.9292 - val_loss: 0.9042 - val_accuracy: 0.7902\n",
            "Epoch 283/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2343 - accuracy: 0.9280 - val_loss: 0.8956 - val_accuracy: 0.8080\n",
            "Epoch 284/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2361 - accuracy: 0.9279 - val_loss: 0.9558 - val_accuracy: 0.7988\n",
            "Epoch 285/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2518 - accuracy: 0.9231 - val_loss: 0.9153 - val_accuracy: 0.7988\n",
            "Epoch 286/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2386 - accuracy: 0.9257 - val_loss: 0.8698 - val_accuracy: 0.8030\n",
            "Epoch 287/300\n",
            "1407/1407 [==============================] - 9s 6ms/step - loss: 0.2375 - accuracy: 0.9253 - val_loss: 0.8928 - val_accuracy: 0.8044\n",
            "Epoch 288/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2488 - accuracy: 0.9232 - val_loss: 0.9296 - val_accuracy: 0.8010\n",
            "Epoch 289/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2318 - accuracy: 0.9281 - val_loss: 0.8466 - val_accuracy: 0.8036\n",
            "Epoch 290/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2393 - accuracy: 0.9260 - val_loss: 0.9104 - val_accuracy: 0.8120\n",
            "Epoch 291/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2375 - accuracy: 0.9255 - val_loss: 0.8491 - val_accuracy: 0.8062\n",
            "Epoch 292/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2378 - accuracy: 0.9254 - val_loss: 0.8570 - val_accuracy: 0.8116\n",
            "Epoch 293/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2370 - accuracy: 0.9276 - val_loss: 0.9157 - val_accuracy: 0.8002\n",
            "Epoch 294/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2348 - accuracy: 0.9275 - val_loss: 0.8758 - val_accuracy: 0.7958\n",
            "Epoch 295/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2360 - accuracy: 0.9288 - val_loss: 0.8160 - val_accuracy: 0.8062\n",
            "Epoch 296/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2392 - accuracy: 0.9266 - val_loss: 0.8345 - val_accuracy: 0.7950\n",
            "Epoch 297/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2331 - accuracy: 0.9277 - val_loss: 0.8459 - val_accuracy: 0.8084\n",
            "Epoch 298/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2367 - accuracy: 0.9262 - val_loss: 0.9299 - val_accuracy: 0.8012\n",
            "Epoch 299/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2313 - accuracy: 0.9291 - val_loss: 0.9150 - val_accuracy: 0.7936\n",
            "Epoch 300/300\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2420 - accuracy: 0.9249 - val_loss: 0.8471 - val_accuracy: 0.8060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f61e4247f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR8j0AbIKS6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_model.save('model900.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqriYBvpxYBK",
        "colab_type": "code",
        "outputId": "300aca34-31fb-43a7-956b-f2d8e7a28b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.imshow(np.squeeze(X_train[0]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f620004a320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha-4Ri9w6YSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rand_array(x, k, in_channels, img_size):\n",
        "    total_num = in_channels * img_size * img_size\n",
        "    x = x.reshape(1, -1)\n",
        "    idx_to_modify = np.random.randint(low=0, high=total_num-1, size=(k,))\n",
        "    gen = np.random.rand(k)\n",
        "    x[0, idx_to_modify] = gen\n",
        "    x = x.reshape(img_size, img_size, in_channels)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjNTZo1IjhqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_synthesize(target_model, fixed_cls, k_max,\n",
        "                    in_channels, img_size):\n",
        "    x = np.random.rand(32,32,3)\n",
        "\n",
        "    y_c_current = 0         # target models probability of fixed class\n",
        "    j = 0                   # consecutive rejections counter\n",
        "    k = k_max               # search radius\n",
        "    max_iter = 50           # max iter number\n",
        "    conf_min = 0.1          # min probability cutoff to consider a record member of the class\n",
        "    rej_max = 5             # max number of consecutive rejections\n",
        "    k_min = 1               # min radius of feature perturbation\n",
        "\n",
        "    for i in range(max_iter):\n",
        "        y = target_model.predict(x.reshape(1,32,32,3))  # query target model\n",
        "        y_c = y.flat[fixed_cls]\n",
        "        # Phase 1: Search\n",
        "        if y_c >= y_c_current:\n",
        "            # Phase 2: Sample\n",
        "            if (y_c > conf_min) and (fixed_cls == np.argmax(y)):\n",
        "                return (x, y)\n",
        "            x_new = x\n",
        "            y_c_current = y_c  # renew variables\n",
        "            j = 0\n",
        "        else:\n",
        "            j += 1\n",
        "            if j > rej_max:  # many consecutive rejects\n",
        "                k = max(k_min, int(np.ceil(k / 2)))\n",
        "                j = 0\n",
        "        x_tmp = rand_array(x_new, k, in_channels, img_size)\n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZygnvYHjdsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while True:\n",
        "  data = data_synthesize(target_model, fixed_cls=8, k_max=3*32*32-1,\n",
        "                    in_channels=3, img_size=32)\n",
        "  if isinstance(data, tuple):\n",
        "    break\n",
        " \n",
        "print(\"########## Example ##########\")\n",
        "print(\"x = \", data[0])\n",
        "print(\"y_c = \", data[1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJZkC-5BMJsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import savetxt\n",
        "def synthesize_batch(target_model, lst_class, n_records):\n",
        "    \"\"\"\n",
        "    Synthesize a batch of records\n",
        "    \"\"\"\n",
        "    x_synth = np.zeros((n_records,32,32,3))\n",
        "    y_synth = np.zeros((n_records, 10))\n",
        "    count = 0\n",
        "    for i in range(n_records//10):\n",
        "      for j in lst_class:\n",
        "        while True:\n",
        "            data = data_synthesize(target_model, fixed_cls=j, k_max=3*32*32-1,\n",
        "                          in_channels=3, img_size=32)\n",
        "            if isinstance(data, tuple):\n",
        "                break\n",
        "      \n",
        "        x_synth[count] = data[0]\n",
        "        y_synth[count] = data[1]\n",
        "        count += 1\n",
        "      if (i % 10 == 0 and i != 0):\n",
        "          np.savez('data' + str(i) +'.npz', x=x_synth, y=y_synth)\n",
        "          print('data'+ str(i) +' has been saved')\n",
        "    return x_synth, y_synth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpEa3c5-okMu",
        "colab_type": "code",
        "outputId": "01a4f33f-57b5-40bf-9b68-a881ebe5e7bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "attack_data = synthesize_batch(target_model, [0,1,2,3,4,5,6,7,8,9], 1000)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data10 has been saved\n",
            "data20 has been saved\n",
            "data30 has been saved\n",
            "data40 has been saved\n",
            "data50 has been saved\n",
            "data60 has been saved\n",
            "data70 has been saved\n",
            "data80 has been saved\n",
            "data90 has been saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiApL_SpZc56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savez('data100.npz', x=attack_data[0], y=attack_data[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuyhCMxl40Dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import load \n",
        "a_d = np.load('data100.npz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxIZZ12PRO3g",
        "colab_type": "code",
        "outputId": "280c7c97-0587-4412-f4b9-47e275871ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# We assume that attacker's data were not seen in target's training.\n",
        "attacker_X_train, attacker_X_test, attacker_y_train, attacker_y_test = train_test_split(\n",
        "    a_d['x'], a_d['y'], test_size=0.1\n",
        ")\n",
        "print(attacker_X_train.shape, attacker_X_test.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(900, 32, 32, 3) (100, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G4EVNLxRiul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SHADOW_DATASET_SIZE = 450\n",
        "\n",
        "# Train the shadow models.\n",
        "smb = ShadowModelBundle(\n",
        "    target_model_fn,\n",
        "    shadow_dataset_size=SHADOW_DATASET_SIZE,\n",
        "    num_models=NUM_SHADOWS,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NScKpGORokl",
        "colab_type": "code",
        "outputId": "054f8729-fb11-467e-ca9d-a2dcef2e0854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"Training the shadow models...\")\n",
        "X_shadow, y_shadow = smb.fit_transform(\n",
        "    attacker_X_train,\n",
        "    attacker_y_train,\n",
        "    fit_kwargs=dict(\n",
        "        epochs=100,\n",
        "        verbose=True,\n",
        "        validation_data=(attacker_X_test, attacker_y_test),\n",
        "    ),\n",
        ")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the shadow models...\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 2.2680 - accuracy: 0.0956 - val_loss: 2.2585 - val_accuracy: 0.1000\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2406 - accuracy: 0.0956 - val_loss: 2.2554 - val_accuracy: 0.1000\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2474 - accuracy: 0.0956 - val_loss: 2.2511 - val_accuracy: 0.1000\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2602 - accuracy: 0.0956 - val_loss: 2.2554 - val_accuracy: 0.1000\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2481 - accuracy: 0.0956 - val_loss: 2.2558 - val_accuracy: 0.1000\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2353 - accuracy: 0.0956 - val_loss: 2.2572 - val_accuracy: 0.1000\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2468 - accuracy: 0.0956 - val_loss: 2.2589 - val_accuracy: 0.1000\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.2535 - accuracy: 0.0956 - val_loss: 2.2545 - val_accuracy: 0.1000\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2366 - accuracy: 0.0956 - val_loss: 2.2507 - val_accuracy: 0.1000\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2224 - accuracy: 0.0956 - val_loss: 2.2539 - val_accuracy: 0.1000\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2394 - accuracy: 0.0956 - val_loss: 2.2520 - val_accuracy: 0.1000\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2405 - accuracy: 0.0956 - val_loss: 2.2518 - val_accuracy: 0.1000\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2381 - accuracy: 0.0956 - val_loss: 2.2527 - val_accuracy: 0.1000\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2429 - accuracy: 0.0956 - val_loss: 2.2529 - val_accuracy: 0.1000\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.2449 - accuracy: 0.0956 - val_loss: 2.2501 - val_accuracy: 0.1000\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.2393 - accuracy: 0.0956 - val_loss: 2.2498 - val_accuracy: 0.1000\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2404 - accuracy: 0.0956 - val_loss: 2.2525 - val_accuracy: 0.1000\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2399 - accuracy: 0.0956 - val_loss: 2.2512 - val_accuracy: 0.1000\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2410 - accuracy: 0.0956 - val_loss: 2.2508 - val_accuracy: 0.1000\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2317 - accuracy: 0.0956 - val_loss: 2.2518 - val_accuracy: 0.1000\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2221 - accuracy: 0.0956 - val_loss: 2.2548 - val_accuracy: 0.1000\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2252 - accuracy: 0.0956 - val_loss: 2.2511 - val_accuracy: 0.1000\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2430 - accuracy: 0.0956 - val_loss: 2.2555 - val_accuracy: 0.1000\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2315 - accuracy: 0.0956 - val_loss: 2.2545 - val_accuracy: 0.1000\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2357 - accuracy: 0.0956 - val_loss: 2.2517 - val_accuracy: 0.1000\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2445 - accuracy: 0.0956 - val_loss: 2.2535 - val_accuracy: 0.1000\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2420 - accuracy: 0.0956 - val_loss: 2.2540 - val_accuracy: 0.1000\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2233 - accuracy: 0.0956 - val_loss: 2.2548 - val_accuracy: 0.1000\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2397 - accuracy: 0.0956 - val_loss: 2.2558 - val_accuracy: 0.1000\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2354 - accuracy: 0.0956 - val_loss: 2.2513 - val_accuracy: 0.1000\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2273 - accuracy: 0.0956 - val_loss: 2.2513 - val_accuracy: 0.1000\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2300 - accuracy: 0.0956 - val_loss: 2.2525 - val_accuracy: 0.1000\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2243 - accuracy: 0.0956 - val_loss: 2.2545 - val_accuracy: 0.1000\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2291 - accuracy: 0.0956 - val_loss: 2.2504 - val_accuracy: 0.1000\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2270 - accuracy: 0.0956 - val_loss: 2.2517 - val_accuracy: 0.1000\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2166 - accuracy: 0.0956 - val_loss: 2.2523 - val_accuracy: 0.1000\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2149 - accuracy: 0.0956 - val_loss: 2.2540 - val_accuracy: 0.1000\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1940 - accuracy: 0.0978 - val_loss: 2.2550 - val_accuracy: 0.1000\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2021 - accuracy: 0.0978 - val_loss: 2.2633 - val_accuracy: 0.1000\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.1912 - accuracy: 0.1067 - val_loss: 2.2605 - val_accuracy: 0.1000\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.1377 - accuracy: 0.1444 - val_loss: 2.2955 - val_accuracy: 0.1000\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1627 - accuracy: 0.1578 - val_loss: 2.2826 - val_accuracy: 0.0900\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1309 - accuracy: 0.1978 - val_loss: 2.2889 - val_accuracy: 0.0900\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.0958 - accuracy: 0.2111 - val_loss: 2.3274 - val_accuracy: 0.0800\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1215 - accuracy: 0.2400 - val_loss: 2.3008 - val_accuracy: 0.0800\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.0349 - accuracy: 0.3000 - val_loss: 2.3416 - val_accuracy: 0.0600\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.0530 - accuracy: 0.3044 - val_loss: 2.3064 - val_accuracy: 0.0800\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.0155 - accuracy: 0.3556 - val_loss: 2.3508 - val_accuracy: 0.0700\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.0140 - accuracy: 0.2844 - val_loss: 2.3270 - val_accuracy: 0.0800\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.9637 - accuracy: 0.3756 - val_loss: 2.3478 - val_accuracy: 0.0400\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.9233 - accuracy: 0.3889 - val_loss: 2.3647 - val_accuracy: 0.0400\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.9160 - accuracy: 0.4244 - val_loss: 2.4014 - val_accuracy: 0.0400\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.9562 - accuracy: 0.3711 - val_loss: 2.3706 - val_accuracy: 0.0900\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.9042 - accuracy: 0.4867 - val_loss: 2.3399 - val_accuracy: 0.0600\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.8012 - accuracy: 0.4600 - val_loss: 2.3903 - val_accuracy: 0.0700\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.8361 - accuracy: 0.5000 - val_loss: 2.3959 - val_accuracy: 0.0900\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.8685 - accuracy: 0.4133 - val_loss: 2.4015 - val_accuracy: 0.0700\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.8392 - accuracy: 0.4622 - val_loss: 2.3639 - val_accuracy: 0.0900\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.8646 - accuracy: 0.4911 - val_loss: 2.4042 - val_accuracy: 0.0700\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8484 - accuracy: 0.5044 - val_loss: 2.3692 - val_accuracy: 0.0600\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7660 - accuracy: 0.5533 - val_loss: 2.3631 - val_accuracy: 0.0800\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7528 - accuracy: 0.5267 - val_loss: 2.4029 - val_accuracy: 0.0800\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7852 - accuracy: 0.5778 - val_loss: 2.3676 - val_accuracy: 0.0600\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7582 - accuracy: 0.6111 - val_loss: 2.4194 - val_accuracy: 0.1100\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7205 - accuracy: 0.5911 - val_loss: 2.4413 - val_accuracy: 0.0400\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7347 - accuracy: 0.5978 - val_loss: 2.4076 - val_accuracy: 0.0700\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7721 - accuracy: 0.5911 - val_loss: 2.4104 - val_accuracy: 0.1000\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7781 - accuracy: 0.5733 - val_loss: 2.4040 - val_accuracy: 0.1100\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7733 - accuracy: 0.6044 - val_loss: 2.4263 - val_accuracy: 0.0600\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7758 - accuracy: 0.5467 - val_loss: 2.4285 - val_accuracy: 0.0700\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7630 - accuracy: 0.6089 - val_loss: 2.4437 - val_accuracy: 0.1100\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7452 - accuracy: 0.5956 - val_loss: 2.4244 - val_accuracy: 0.0600\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7480 - accuracy: 0.5889 - val_loss: 2.3909 - val_accuracy: 0.0800\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7483 - accuracy: 0.6156 - val_loss: 2.3987 - val_accuracy: 0.0800\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7217 - accuracy: 0.6400 - val_loss: 2.4106 - val_accuracy: 0.0800\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6875 - accuracy: 0.5933 - val_loss: 2.4275 - val_accuracy: 0.1000\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7413 - accuracy: 0.5867 - val_loss: 2.4031 - val_accuracy: 0.0800\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6783 - accuracy: 0.6289 - val_loss: 2.4051 - val_accuracy: 0.0900\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6553 - accuracy: 0.6067 - val_loss: 2.4242 - val_accuracy: 0.0800\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7258 - accuracy: 0.6444 - val_loss: 2.4352 - val_accuracy: 0.1200\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7461 - accuracy: 0.6022 - val_loss: 2.4093 - val_accuracy: 0.0700\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6950 - accuracy: 0.6444 - val_loss: 2.4077 - val_accuracy: 0.0500\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6747 - accuracy: 0.6400 - val_loss: 2.4168 - val_accuracy: 0.0900\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6898 - accuracy: 0.6644 - val_loss: 2.3870 - val_accuracy: 0.0700\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6524 - accuracy: 0.6422 - val_loss: 2.3790 - val_accuracy: 0.0600\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6523 - accuracy: 0.6733 - val_loss: 2.3860 - val_accuracy: 0.0900\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.7224 - accuracy: 0.6600 - val_loss: 2.3945 - val_accuracy: 0.0700\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.6588 - accuracy: 0.6756 - val_loss: 2.3671 - val_accuracy: 0.0600\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6704 - accuracy: 0.6533 - val_loss: 2.4242 - val_accuracy: 0.0900\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6746 - accuracy: 0.6867 - val_loss: 2.3809 - val_accuracy: 0.0500\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6534 - accuracy: 0.6511 - val_loss: 2.4147 - val_accuracy: 0.0700\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6717 - accuracy: 0.6600 - val_loss: 2.4109 - val_accuracy: 0.0600\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6694 - accuracy: 0.6556 - val_loss: 2.3936 - val_accuracy: 0.0700\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6320 - accuracy: 0.6733 - val_loss: 2.3743 - val_accuracy: 0.0700\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6806 - accuracy: 0.6978 - val_loss: 2.3917 - val_accuracy: 0.0500\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6162 - accuracy: 0.6711 - val_loss: 2.4161 - val_accuracy: 0.0700\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6589 - accuracy: 0.6889 - val_loss: 2.3730 - val_accuracy: 0.0600\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6109 - accuracy: 0.7044 - val_loss: 2.3647 - val_accuracy: 0.0700\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6607 - accuracy: 0.6933 - val_loss: 2.4021 - val_accuracy: 0.0800\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6306 - accuracy: 0.6667 - val_loss: 2.3863 - val_accuracy: 0.0600\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 2.2564 - accuracy: 0.1156 - val_loss: 2.2504 - val_accuracy: 0.1000\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2156 - accuracy: 0.1022 - val_loss: 2.2565 - val_accuracy: 0.1000\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2520 - accuracy: 0.1022 - val_loss: 2.2593 - val_accuracy: 0.1000\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2213 - accuracy: 0.1044 - val_loss: 2.2518 - val_accuracy: 0.1000\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2285 - accuracy: 0.1044 - val_loss: 2.2548 - val_accuracy: 0.1000\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2421 - accuracy: 0.1044 - val_loss: 2.2523 - val_accuracy: 0.1000\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2228 - accuracy: 0.1044 - val_loss: 2.2470 - val_accuracy: 0.1000\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2283 - accuracy: 0.1044 - val_loss: 2.2491 - val_accuracy: 0.1000\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2356 - accuracy: 0.1044 - val_loss: 2.2507 - val_accuracy: 0.1000\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2327 - accuracy: 0.1044 - val_loss: 2.2484 - val_accuracy: 0.1000\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2278 - accuracy: 0.1044 - val_loss: 2.2488 - val_accuracy: 0.1000\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2251 - accuracy: 0.1044 - val_loss: 2.2463 - val_accuracy: 0.1000\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2318 - accuracy: 0.1044 - val_loss: 2.2468 - val_accuracy: 0.1000\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.2154 - accuracy: 0.1044 - val_loss: 2.2548 - val_accuracy: 0.1000\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2241 - accuracy: 0.1044 - val_loss: 2.2475 - val_accuracy: 0.1000\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2354 - accuracy: 0.1044 - val_loss: 2.2476 - val_accuracy: 0.1000\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2375 - accuracy: 0.1044 - val_loss: 2.2486 - val_accuracy: 0.1000\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2353 - accuracy: 0.1044 - val_loss: 2.2508 - val_accuracy: 0.1000\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2320 - accuracy: 0.1044 - val_loss: 2.2517 - val_accuracy: 0.1000\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2294 - accuracy: 0.1044 - val_loss: 2.2526 - val_accuracy: 0.1000\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2293 - accuracy: 0.1044 - val_loss: 2.2461 - val_accuracy: 0.1000\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2289 - accuracy: 0.1044 - val_loss: 2.2479 - val_accuracy: 0.1000\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2215 - accuracy: 0.1044 - val_loss: 2.2518 - val_accuracy: 0.1000\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2105 - accuracy: 0.1044 - val_loss: 2.2496 - val_accuracy: 0.1000\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2201 - accuracy: 0.1044 - val_loss: 2.2498 - val_accuracy: 0.1000\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2098 - accuracy: 0.1044 - val_loss: 2.2504 - val_accuracy: 0.1000\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2241 - accuracy: 0.1044 - val_loss: 2.2491 - val_accuracy: 0.1000\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2271 - accuracy: 0.1044 - val_loss: 2.2491 - val_accuracy: 0.1000\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2297 - accuracy: 0.1044 - val_loss: 2.2474 - val_accuracy: 0.1000\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2260 - accuracy: 0.1044 - val_loss: 2.2437 - val_accuracy: 0.1000\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2159 - accuracy: 0.1044 - val_loss: 2.2508 - val_accuracy: 0.1000\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2144 - accuracy: 0.1044 - val_loss: 2.2515 - val_accuracy: 0.1000\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1849 - accuracy: 0.1044 - val_loss: 2.2539 - val_accuracy: 0.1000\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2243 - accuracy: 0.1044 - val_loss: 2.2486 - val_accuracy: 0.1000\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1997 - accuracy: 0.1044 - val_loss: 2.2573 - val_accuracy: 0.1000\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1794 - accuracy: 0.1133 - val_loss: 2.2631 - val_accuracy: 0.1000\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1686 - accuracy: 0.1422 - val_loss: 2.2606 - val_accuracy: 0.1000\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1606 - accuracy: 0.1622 - val_loss: 2.2767 - val_accuracy: 0.0900\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1353 - accuracy: 0.1867 - val_loss: 2.2717 - val_accuracy: 0.0800\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1022 - accuracy: 0.2089 - val_loss: 2.3137 - val_accuracy: 0.0800\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.0884 - accuracy: 0.2133 - val_loss: 2.3020 - val_accuracy: 0.1100\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.0814 - accuracy: 0.2133 - val_loss: 2.2837 - val_accuracy: 0.1100\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.0815 - accuracy: 0.2489 - val_loss: 2.3095 - val_accuracy: 0.0900\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.0392 - accuracy: 0.3022 - val_loss: 2.2892 - val_accuracy: 0.0900\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.9913 - accuracy: 0.3200 - val_loss: 2.3240 - val_accuracy: 0.0800\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.9703 - accuracy: 0.3444 - val_loss: 2.4038 - val_accuracy: 0.0800\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.9538 - accuracy: 0.3800 - val_loss: 2.2981 - val_accuracy: 0.0900\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.9319 - accuracy: 0.4022 - val_loss: 2.3402 - val_accuracy: 0.0900\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.9117 - accuracy: 0.3956 - val_loss: 2.3441 - val_accuracy: 0.1400\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.8187 - accuracy: 0.4800 - val_loss: 2.3706 - val_accuracy: 0.1100\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8171 - accuracy: 0.4844 - val_loss: 2.3367 - val_accuracy: 0.0800\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7962 - accuracy: 0.5156 - val_loss: 2.3586 - val_accuracy: 0.1000\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7980 - accuracy: 0.5022 - val_loss: 2.3721 - val_accuracy: 0.1000\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7836 - accuracy: 0.5333 - val_loss: 2.3610 - val_accuracy: 0.1600\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7565 - accuracy: 0.5400 - val_loss: 2.3928 - val_accuracy: 0.0600\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7700 - accuracy: 0.5489 - val_loss: 2.3716 - val_accuracy: 0.1000\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7105 - accuracy: 0.5467 - val_loss: 2.4224 - val_accuracy: 0.1300\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7282 - accuracy: 0.6067 - val_loss: 2.3765 - val_accuracy: 0.0700\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7423 - accuracy: 0.6022 - val_loss: 2.3718 - val_accuracy: 0.1400\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7226 - accuracy: 0.5933 - val_loss: 2.3626 - val_accuracy: 0.1100\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6716 - accuracy: 0.6400 - val_loss: 2.3575 - val_accuracy: 0.1000\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6703 - accuracy: 0.5733 - val_loss: 2.3755 - val_accuracy: 0.0900\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6879 - accuracy: 0.6511 - val_loss: 2.3626 - val_accuracy: 0.1000\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6899 - accuracy: 0.6222 - val_loss: 2.3367 - val_accuracy: 0.1400\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6534 - accuracy: 0.6267 - val_loss: 2.3837 - val_accuracy: 0.0900\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6507 - accuracy: 0.6689 - val_loss: 2.3753 - val_accuracy: 0.1100\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6702 - accuracy: 0.6444 - val_loss: 2.3883 - val_accuracy: 0.1300\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6646 - accuracy: 0.6533 - val_loss: 2.3948 - val_accuracy: 0.1000\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6581 - accuracy: 0.6622 - val_loss: 2.4326 - val_accuracy: 0.1500\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6550 - accuracy: 0.6578 - val_loss: 2.3910 - val_accuracy: 0.1200\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6087 - accuracy: 0.6756 - val_loss: 2.3720 - val_accuracy: 0.1000\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6685 - accuracy: 0.6267 - val_loss: 2.3644 - val_accuracy: 0.1000\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6706 - accuracy: 0.6578 - val_loss: 2.3489 - val_accuracy: 0.0800\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6520 - accuracy: 0.6733 - val_loss: 2.3582 - val_accuracy: 0.1300\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6129 - accuracy: 0.6778 - val_loss: 2.3899 - val_accuracy: 0.0900\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6566 - accuracy: 0.6733 - val_loss: 2.3833 - val_accuracy: 0.1100\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6867 - accuracy: 0.6000 - val_loss: 2.3359 - val_accuracy: 0.1100\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6611 - accuracy: 0.6200 - val_loss: 2.3695 - val_accuracy: 0.1100\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6580 - accuracy: 0.6467 - val_loss: 2.3576 - val_accuracy: 0.1300\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6121 - accuracy: 0.6711 - val_loss: 2.3635 - val_accuracy: 0.1300\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6451 - accuracy: 0.6844 - val_loss: 2.3545 - val_accuracy: 0.1100\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6396 - accuracy: 0.6689 - val_loss: 2.3454 - val_accuracy: 0.1000\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6256 - accuracy: 0.6756 - val_loss: 2.3647 - val_accuracy: 0.1200\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6380 - accuracy: 0.6978 - val_loss: 2.3360 - val_accuracy: 0.1300\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6178 - accuracy: 0.6933 - val_loss: 2.3504 - val_accuracy: 0.1100\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5870 - accuracy: 0.6689 - val_loss: 2.3428 - val_accuracy: 0.1300\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6276 - accuracy: 0.7333 - val_loss: 2.3379 - val_accuracy: 0.1000\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6016 - accuracy: 0.6822 - val_loss: 2.3264 - val_accuracy: 0.1000\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6279 - accuracy: 0.6867 - val_loss: 2.3485 - val_accuracy: 0.1200\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6165 - accuracy: 0.6778 - val_loss: 2.3506 - val_accuracy: 0.0900\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6253 - accuracy: 0.6933 - val_loss: 2.3600 - val_accuracy: 0.1000\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.4925 - accuracy: 0.7044 - val_loss: 2.3643 - val_accuracy: 0.0500\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5610 - accuracy: 0.7067 - val_loss: 2.3566 - val_accuracy: 0.1200\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5842 - accuracy: 0.7089 - val_loss: 2.4029 - val_accuracy: 0.0800\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5904 - accuracy: 0.6889 - val_loss: 2.3513 - val_accuracy: 0.1300\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5168 - accuracy: 0.7022 - val_loss: 2.3478 - val_accuracy: 0.1200\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5336 - accuracy: 0.7067 - val_loss: 2.3504 - val_accuracy: 0.1100\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.5588 - accuracy: 0.7444 - val_loss: 2.3617 - val_accuracy: 0.1000\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6079 - accuracy: 0.6933 - val_loss: 2.3556 - val_accuracy: 0.0900\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5633 - accuracy: 0.6933 - val_loss: 2.3647 - val_accuracy: 0.0900\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 2.2467 - accuracy: 0.1178 - val_loss: 2.2660 - val_accuracy: 0.1000\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2531 - accuracy: 0.1022 - val_loss: 2.2542 - val_accuracy: 0.1000\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2279 - accuracy: 0.1022 - val_loss: 2.2555 - val_accuracy: 0.1000\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2428 - accuracy: 0.1022 - val_loss: 2.2548 - val_accuracy: 0.1000\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2654 - accuracy: 0.1022 - val_loss: 2.2528 - val_accuracy: 0.1000\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2479 - accuracy: 0.1022 - val_loss: 2.2589 - val_accuracy: 0.1000\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2385 - accuracy: 0.1022 - val_loss: 2.2600 - val_accuracy: 0.1000\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2300 - accuracy: 0.1022 - val_loss: 2.2553 - val_accuracy: 0.1000\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2402 - accuracy: 0.1022 - val_loss: 2.2483 - val_accuracy: 0.1000\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2274 - accuracy: 0.1022 - val_loss: 2.2496 - val_accuracy: 0.1000\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2312 - accuracy: 0.1022 - val_loss: 2.2532 - val_accuracy: 0.1000\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2352 - accuracy: 0.1022 - val_loss: 2.2530 - val_accuracy: 0.1000\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2342 - accuracy: 0.1022 - val_loss: 2.2521 - val_accuracy: 0.1000\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2400 - accuracy: 0.1022 - val_loss: 2.2524 - val_accuracy: 0.1000\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2427 - accuracy: 0.1022 - val_loss: 2.2542 - val_accuracy: 0.1000\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2288 - accuracy: 0.1022 - val_loss: 2.2541 - val_accuracy: 0.1000\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2465 - accuracy: 0.1022 - val_loss: 2.2539 - val_accuracy: 0.1000\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2445 - accuracy: 0.1022 - val_loss: 2.2500 - val_accuracy: 0.1000\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2309 - accuracy: 0.1022 - val_loss: 2.2521 - val_accuracy: 0.1000\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2348 - accuracy: 0.1022 - val_loss: 2.2507 - val_accuracy: 0.1000\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2252 - accuracy: 0.1022 - val_loss: 2.2535 - val_accuracy: 0.1000\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2193 - accuracy: 0.1022 - val_loss: 2.2529 - val_accuracy: 0.1000\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2381 - accuracy: 0.1022 - val_loss: 2.2523 - val_accuracy: 0.1000\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2345 - accuracy: 0.1022 - val_loss: 2.2532 - val_accuracy: 0.1000\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2318 - accuracy: 0.1022 - val_loss: 2.2539 - val_accuracy: 0.1000\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2371 - accuracy: 0.1022 - val_loss: 2.2538 - val_accuracy: 0.1000\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2157 - accuracy: 0.1022 - val_loss: 2.2535 - val_accuracy: 0.1000\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2418 - accuracy: 0.1022 - val_loss: 2.2540 - val_accuracy: 0.1000\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.2338 - accuracy: 0.1022 - val_loss: 2.2535 - val_accuracy: 0.1000\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2314 - accuracy: 0.1022 - val_loss: 2.2544 - val_accuracy: 0.1000\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2269 - accuracy: 0.1022 - val_loss: 2.2508 - val_accuracy: 0.1000\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2290 - accuracy: 0.1022 - val_loss: 2.2511 - val_accuracy: 0.1000\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2265 - accuracy: 0.1022 - val_loss: 2.2505 - val_accuracy: 0.1000\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2251 - accuracy: 0.1022 - val_loss: 2.2530 - val_accuracy: 0.1000\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2206 - accuracy: 0.1022 - val_loss: 2.2512 - val_accuracy: 0.1000\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2399 - accuracy: 0.1022 - val_loss: 2.2502 - val_accuracy: 0.1000\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2279 - accuracy: 0.1022 - val_loss: 2.2492 - val_accuracy: 0.1000\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2044 - accuracy: 0.1022 - val_loss: 2.2501 - val_accuracy: 0.1000\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2255 - accuracy: 0.1022 - val_loss: 2.2522 - val_accuracy: 0.1000\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2292 - accuracy: 0.1022 - val_loss: 2.2532 - val_accuracy: 0.1000\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2190 - accuracy: 0.1022 - val_loss: 2.2550 - val_accuracy: 0.1000\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2151 - accuracy: 0.1022 - val_loss: 2.2556 - val_accuracy: 0.1000\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2375 - accuracy: 0.1022 - val_loss: 2.2497 - val_accuracy: 0.1000\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2209 - accuracy: 0.1022 - val_loss: 2.2488 - val_accuracy: 0.1000\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2134 - accuracy: 0.1022 - val_loss: 2.2494 - val_accuracy: 0.1000\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1999 - accuracy: 0.1022 - val_loss: 2.2489 - val_accuracy: 0.1000\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1677 - accuracy: 0.1044 - val_loss: 2.2531 - val_accuracy: 0.1000\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1845 - accuracy: 0.1044 - val_loss: 2.2576 - val_accuracy: 0.1000\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1718 - accuracy: 0.1244 - val_loss: 2.2489 - val_accuracy: 0.1000\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1401 - accuracy: 0.1400 - val_loss: 2.2637 - val_accuracy: 0.1100\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1084 - accuracy: 0.1867 - val_loss: 2.2621 - val_accuracy: 0.0900\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.0610 - accuracy: 0.2378 - val_loss: 2.2826 - val_accuracy: 0.1000\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1099 - accuracy: 0.2089 - val_loss: 2.2847 - val_accuracy: 0.1200\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.0562 - accuracy: 0.2733 - val_loss: 2.3046 - val_accuracy: 0.1200\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.0603 - accuracy: 0.2867 - val_loss: 2.2804 - val_accuracy: 0.1200\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.0393 - accuracy: 0.2733 - val_loss: 2.3182 - val_accuracy: 0.1500\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.9462 - accuracy: 0.3133 - val_loss: 2.3516 - val_accuracy: 0.1000\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.9662 - accuracy: 0.3844 - val_loss: 2.3150 - val_accuracy: 0.0700\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.9161 - accuracy: 0.4044 - val_loss: 2.3597 - val_accuracy: 0.0700\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8772 - accuracy: 0.4178 - val_loss: 2.3645 - val_accuracy: 0.1200\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.8880 - accuracy: 0.4178 - val_loss: 2.3857 - val_accuracy: 0.1400\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.8363 - accuracy: 0.4400 - val_loss: 2.4039 - val_accuracy: 0.1100\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7711 - accuracy: 0.4867 - val_loss: 2.3613 - val_accuracy: 0.1100\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7329 - accuracy: 0.5244 - val_loss: 2.3601 - val_accuracy: 0.1100\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7754 - accuracy: 0.5311 - val_loss: 2.4264 - val_accuracy: 0.1000\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7311 - accuracy: 0.4889 - val_loss: 2.4335 - val_accuracy: 0.1200\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7213 - accuracy: 0.5244 - val_loss: 2.4299 - val_accuracy: 0.1200\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7841 - accuracy: 0.5489 - val_loss: 2.4240 - val_accuracy: 0.1300\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7059 - accuracy: 0.5822 - val_loss: 2.4072 - val_accuracy: 0.1300\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7689 - accuracy: 0.5578 - val_loss: 2.4082 - val_accuracy: 0.1200\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7250 - accuracy: 0.5333 - val_loss: 2.4434 - val_accuracy: 0.1000\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7455 - accuracy: 0.5622 - val_loss: 2.4434 - val_accuracy: 0.1000\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7139 - accuracy: 0.5444 - val_loss: 2.4426 - val_accuracy: 0.0900\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6609 - accuracy: 0.5933 - val_loss: 2.4261 - val_accuracy: 0.0900\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6717 - accuracy: 0.5556 - val_loss: 2.4473 - val_accuracy: 0.1100\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6327 - accuracy: 0.6133 - val_loss: 2.4447 - val_accuracy: 0.1200\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6837 - accuracy: 0.5822 - val_loss: 2.3960 - val_accuracy: 0.1100\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6166 - accuracy: 0.6289 - val_loss: 2.4109 - val_accuracy: 0.0800\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6458 - accuracy: 0.6556 - val_loss: 2.4248 - val_accuracy: 0.1200\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6139 - accuracy: 0.6000 - val_loss: 2.4613 - val_accuracy: 0.0900\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6334 - accuracy: 0.6644 - val_loss: 2.4421 - val_accuracy: 0.1200\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6562 - accuracy: 0.6378 - val_loss: 2.4255 - val_accuracy: 0.0900\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5296 - accuracy: 0.6444 - val_loss: 2.4391 - val_accuracy: 0.1000\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6092 - accuracy: 0.6800 - val_loss: 2.4141 - val_accuracy: 0.1300\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.5051 - accuracy: 0.6556 - val_loss: 2.4597 - val_accuracy: 0.1600\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5527 - accuracy: 0.6600 - val_loss: 2.4064 - val_accuracy: 0.1200\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5850 - accuracy: 0.7089 - val_loss: 2.4421 - val_accuracy: 0.1300\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5390 - accuracy: 0.6644 - val_loss: 2.3904 - val_accuracy: 0.1300\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5692 - accuracy: 0.7178 - val_loss: 2.4203 - val_accuracy: 0.1300\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5771 - accuracy: 0.7222 - val_loss: 2.4067 - val_accuracy: 0.1000\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5888 - accuracy: 0.6711 - val_loss: 2.3794 - val_accuracy: 0.1700\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5349 - accuracy: 0.6556 - val_loss: 2.4339 - val_accuracy: 0.1400\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5990 - accuracy: 0.6756 - val_loss: 2.4012 - val_accuracy: 0.1400\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5804 - accuracy: 0.6778 - val_loss: 2.3807 - val_accuracy: 0.1300\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5496 - accuracy: 0.7111 - val_loss: 2.4493 - val_accuracy: 0.1000\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5982 - accuracy: 0.6578 - val_loss: 2.3618 - val_accuracy: 0.1300\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6048 - accuracy: 0.6733 - val_loss: 2.4165 - val_accuracy: 0.1100\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5950 - accuracy: 0.7022 - val_loss: 2.3986 - val_accuracy: 0.1200\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5475 - accuracy: 0.6800 - val_loss: 2.3923 - val_accuracy: 0.1600\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6000 - accuracy: 0.6711 - val_loss: 2.3776 - val_accuracy: 0.1100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XuePRZ9RvUy",
        "colab_type": "code",
        "outputId": "c1dc4634-db22-46c5-e4dd-c28eca2c0dc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# ShadowModelBundle returns data in the format suitable for the AttackModelBundle.\n",
        "amb = AttackModelBundle(attack_model_fn, num_classes=NUM_CLASSES)\n",
        "\n",
        "# Fit the attack models.\n",
        "print(\"Training the attack models...\")\n",
        "amb.fit(\n",
        "    X_shadow, y_shadow, fit_kwargs=dict(epochs=20, verbose=True)\n",
        ")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the attack models...\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.6989\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.8853\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.8889\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.8781\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8996\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.9068\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.9104\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.2398 - accuracy: 0.9068\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.9068\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2294 - accuracy: 0.9032\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.2310 - accuracy: 0.8961\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2345 - accuracy: 0.9104\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.9104\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9211\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9176\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9319\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9176\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9211\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.2297 - accuracy: 0.9032\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.2150 - accuracy: 0.9176\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.5861\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.7985\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.9194\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.9304\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.9341\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.9304\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.9231\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9377\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.9267\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.9451\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9451\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1576 - accuracy: 0.9634\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9267\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1395 - accuracy: 0.9377\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1847 - accuracy: 0.9231\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9377\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9524\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1629 - accuracy: 0.9377\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9414\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9487\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.5471\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6594\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7790\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.8732\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.9130\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.9167\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9239\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.2111 - accuracy: 0.9203\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1774 - accuracy: 0.9420\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9348\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9239\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9167\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9384\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.9239\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9384\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9384\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9239\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9348\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 0.9239\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.9493\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.7355\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.6462 - accuracy: 0.8913\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.8696\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.8804\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8768\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8913\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.9058\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9094\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.8913\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9167\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9130\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9130\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2021 - accuracy: 0.9167\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9275\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9167\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.9058\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1806 - accuracy: 0.9203\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9312\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.9384\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9167\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6783 - accuracy: 0.7826\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.8370\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.8913\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.8913\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.9203\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.9130\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.9203\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9312\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9420\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1695 - accuracy: 0.9239\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.9384\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.9312\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.9275\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9312\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9312\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9348\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9239\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.9312\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9167\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9275\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.6292\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.8315\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.8914\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.8989\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9251\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.9438\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.9251\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1774 - accuracy: 0.9513\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1662 - accuracy: 0.9438\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1165 - accuracy: 0.9663\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.9625\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.9625\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9588\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 0.9700\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9625\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 0.9625\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.9738\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.9775\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9775\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.9663\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.5889\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.8111\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.8926\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.9000\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.9148\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.9222\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2392 - accuracy: 0.9148\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.2156 - accuracy: 0.9111\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9185\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9185\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.9222\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9259\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9037\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9333\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9148\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9185\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9222\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9148\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1683 - accuracy: 0.9259\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1894 - accuracy: 0.9222\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5758\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.6568 - accuracy: 0.7917\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.8447\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.8939\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.9242\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2866 - accuracy: 0.9167\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.9129\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1919 - accuracy: 0.9318\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9394\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.9242\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1561 - accuracy: 0.9545\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9508\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9280\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9318\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9545\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9432\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.9356\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1149 - accuracy: 0.9583\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9432\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9470\n",
            "Epoch 1/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.7063\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.9008\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.9246\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.9206\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.9325\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.9286\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.9444\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1706 - accuracy: 0.9603\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9524\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1226 - accuracy: 0.9603\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.9563\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1000 - accuracy: 0.9643\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.9802\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 0.9643\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9722\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0899 - accuracy: 0.9722\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9762\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.9762\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9802\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.9762\n",
            "Epoch 1/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.8015\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.9438\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.9625\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.9625\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 0.9663\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9738\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 0.9663\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9738\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9738\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.9625\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9775\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9888\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9850\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9888\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9813\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9850\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9813\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9888\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 0.9738\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON9UVKtGR_71",
        "colab_type": "code",
        "outputId": "2dfda3b0-80b9-41b7-b567-f5fbf4014eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Test the success of the attack.\n",
        "ATTACK_TEST_DATASET_SIZE = 4000\n",
        "# Prepare examples that were in the training, and out of the training.\n",
        "data_in = X_train[:ATTACK_TEST_DATASET_SIZE], y_train[:ATTACK_TEST_DATASET_SIZE]\n",
        "data_out = X_test[:ATTACK_TEST_DATASET_SIZE], y_test[:ATTACK_TEST_DATASET_SIZE]\n",
        "# data_out = np.concatenate((X_test, a_X_train), axis=0), np.concatenate((y_test, a_y_train), axis=0)\n",
        "\n",
        "\n",
        "# Compile them into the expected format for the AttackModelBundle.\n",
        "attack_test_data, real_membership_labels = prepare_attack_data(\n",
        "    target_model, data_in, data_out\n",
        ")\n",
        "\n",
        "# Compute the attack accuracy.\n",
        "attack_guesses = amb.predict(attack_test_data)\n",
        "attack_accuracy = np.mean(attack_guesses == real_membership_labels)\n",
        "print(attack_accuracy)\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.555625\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}